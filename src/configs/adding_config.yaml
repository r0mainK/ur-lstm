## Task config

# Sequence length
seq_length: 2000

# -------------------------------------------------------------------------------------------------

## Model config

# Hidden dim of the LSTM
hidden_dim: 256
# Model type, one of lstm, u-lstm, r-lstm, ur-lstm
model_type: ur-lstm
# Initial forget bias, only used for lstm and r-lstm variants (set to null for regular init)
forget_bias: 1.

# -------------------------------------------------------------------------------------------------

## Train config

# Batch size
batch_size: 10
# Adam learning rate
learning_rate: 0.001
# Number of training steps
n_steps: 100000
# Random seed
seed: 22
